---
layout: post
title: "섹션8. 딥러닝의 기본 개념과, 문제, 그리고 해결"
date: 2019-02-18 17:46:00
image: '/assets/img/ML/intro.jpeg'
description: ML study
category: 'Machine Learning'
tags:
- Machine Learning
twitter_text: Lorem ipsum dolor sit amet, consectetur adipisicing elit.
introduction: A summary of what i studied
---


## 섹션8. 딥러닝의 기본 개념과, 문제, 그리고 해결

### 00x Activation Function

![problem](/assets/img/ML/section8/fig1.PNG "Activation Function")
<center><font size="0.5em">(Fig 1. Activation Function)</font></center><br>

실제 뇌 속 뉴런은 여러 신호들이 들어오고 이 신호들의 합이 특정 값을 넘을 경우 1 아니면 0 값을 다시 신호로 내보내는 구조이다.

![problem](/assets/img/ML/section8/fig2.PNG "Logistic regression units")
<center><font size="0.5em">(Fig 2. Logistic regression units)</font></center><br>

Activation function처럼 Logistic regression도 layer를 나눠 구조화 시킬 수 있다.

### 01x XOR problem(not linearly separable)

![problem](/assets/img/ML/section8/fig3.PNG "Multi layer Perceptrons")
<center><font size="0.5em">(Fig 3. Multi layer Perceptrons)</font></center><br>

XOR의 경우 linear하지 않아 이를 예측할 수 없다. 그러나 이를 해결하기 위해 여러개의 layer를 통해 위 문제를 해결할 수 있는데 처음에는 이를 학습할 수 있는 방법이 없었다.

![problem](/assets/img/ML/section8/fig4.PNG "Backprogration")
<center><font size="0.5em">(Fig 4. Backprogration)</font></center><br>

이를 해결하기 위해 error가 발생하면 뒤로 에러를 전달하면서 해결되었다(Backprogation).

### 02x Convolutional Neural Networks

![problem](/assets/img/ML/section8/fig5.PNG "Backprogration")
<center><font size="0.5em">(Fig 5. CNN)</font></center><br>

만약 그림이 있으면 한번에 전부를 인식하는게 아니라 부분을 나눠서 분석하고 이를 다시 합치는 방식으로 하는 것을 CNN이라고 한다(글자 읽기, 자율주행 등장).

그러나 Neural Networks도 layer가 많아질 경우 잘 동작하지 않는 문제점이 발생하였다.

### 03x Deep의 등장

초기 W값이 적절하다면 Layer가 많아져도 잘 학습되는 것이 확인되어 여러 Layer로 이루어진 Deep한 신경망을 구성할 수 있게 되었다.