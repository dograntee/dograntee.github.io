---
layout: post
title: "섹션7. ML의 실용과 몇가지 팁"
date: 2019-02-17 16:43:00
image: '/assets/img/ML/intro.jpeg'
description: ML study
category: 'Machine Learning'
tags:
- Machine Learning
twitter_text: Lorem ipsum dolor sit amet, consectetur adipisicing elit.
introduction: A summary of what i studied
---


## 섹션7. ML의 실용과 몇가지 팁

### 00xLearaning rates 

Gradient를 이용해서 cost가 최소가 되는 값을 찾을 때 learning_rate라는 값이 포함된다. 이 값이 너무 클 경우, 도달해야하는 값을 상당히 넘어서 다음 값을 계산할 수 있다. 이러한 현상을 Overshooting이라고 한다. 반대로 이 값이 너무 작을 경우 극값에 도달하기 위해 시간이 많이 필요하다.

따라서 learning rate는 적절하게 산정해야하는데, 이를 위해 실제로 몇몇 값을 학습시켜서 cost값이 어떻게 변화하는 지 본 뒤 산정하는게 좋은 방법이다.

### 01x Data Preprocessing

![problem](/assets/img/ML/section7/fig1.PNG "Data Preprocessing")
<center><font size="0.5em">(Fig 1. Data Preprocessing)</font></center><br>

입력값이 2개 이상 필요할 때, 두 값에 사용되는 값의 범위 차이가 크다면 이를 Normalization 처리를 해줘야한다. learning rate도 적당히 산정해주었는데도 학습이 되지 않는다면 Normalization이 필요한지 고려해보아야 한다.

### 02x Normalization 위한 방법(Standardization)

![problem](/assets/img/ML/section7/fig2.PNG "Normalization 위한 방법")
<center><font size="0.5em">(Fig 2. Normalization 위한 방법)</font></center><br>

Normalization을 위한 방법은 다양한데, 위는 평균이 0, 분산이 1이 되도록하는 표준화식이다. 이를 통해서 Normalization 가능.

### 03x Overfitting

학습된 데이터에 대한 결과는 잘 예측하지만 실제 데이터에서 예외가 더 잘 발생하는 경우를 Overfitting이라고 한다(학습 데이터에만 최적화). 이를 해결하기 위해서는 크게 3가지 방법을 사용한다. 하나는 학습 데이터를 많이 포함하는 것이고 다른 하나는 feature의 수를 줄이는 것이다(중복된 feautre 등). 나머지 하나는 Regularization이다.

### 04x Regularization

![problem](/assets/img/ML/section7/fig3.PNG "Regularization")
<center><font size="0.5em">(Fig 3. Regularization)</font></center><br>

Regularization이란 Cost함수에 W 제곱의 합과 특정값을 곱함 식을 더함으로서 실제 생성되는 Hypothesis 함수의 개형을 좀 더 평평하게 만들 수 있다.

### 05x Evaluation

![problem](/assets/img/ML/section7/fig4.PNG "Evaluation")
<center><font size="0.5em">(Fig 4. Evaluation)</font></center><br>

모든 데이터셋을 활용하여 학습하는 것이 아닌 조금 남겨두어 학습한 뒤 남겨둔 부분으로 학습을 평가한다.

### 06x Online Learning

![problem](/assets/img/ML/section7/fig5.PNG "Online Learning")
<center><font size="0.5em">(Fig 5. Evaluation)</font></center><br>

데이터가 너무 많을 때 Online Learning을 사용한다. 이러한 방식은 학습을 진행할 때 데이터셋이 추가되거나 변화되어도 전부 새로 진행하는 것이 아닌, 해당하는 데이터셋만 추가적으로 학습을 진행시킨다.