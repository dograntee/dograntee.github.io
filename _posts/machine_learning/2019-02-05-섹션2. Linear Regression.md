---
layout: post
title: "섹션2. Linear Regression"
date: 2019-02-05 18:06:00
image: '/assets/img/ML/intro.jpeg'
description: ML study
category: 'pwnable'
tags:
- Machine Learning
twitter_text: Lorem ipsum dolor sit amet, consectetur adipisicing elit.
introduction: A summary of what i studied
---

## 섹션2. Linear Regression

### 00xPredicting exam score(regression)

 X(hours) | Y(score)
 ---- | ----
 10 | 90
 9 | 80
 3 | 50
 2 | 30

 위와 같은 데이터를 토대로 학습하는 경우를 앞서 말했듯이 regression이라고 하고 Label(y값)을 가지고 있기 때문에 supervised learning이다.

### 01xRegression example

 ![problem](/assets/img/ML/section2/figure1.PNG "Linear graph")
<center><font size="0.5em">(Fig 1. Linear graph)</font></center><br>

<center><b>"H(x) = Wx + b"로 도출되는 가정 식 중 가장 올바른 W와 b를 찾아야한다.</b></center><br>

위와 같은 데이터셋은 X값이 크면 클수록 Y값이 증가하는 Linear하게 변화한다고 볼 수 있다. 이때 주어진 데이터를 이용하여 선을 찾는 것을 Linear regression이라고 한다.<br>

### 02xCost function

<center><b>"(H(x) -y)"제곱의 평균</b></center><br>
<center><b>cost(W,b)<br>minimize cost(W,b)</b></center><br>

도출되는 가설식과 실제 trainig data와의 차이를 나타내는 함수를 Cost fuction 또는 Loss function이라고 부른다. 유추하는 값과 실제 데이터의 차이가 음수 양수를 고려하지 않고 차이가 존재할때를 의미하게끔 하기 위해서 제곱을 한 뒤 평균을 구한다.<br>
H(x)에 "Wx + b" 를 위 식에 대입하면 결국 cost함수는 W와 b에 따라 값이 바뀌고 두번째, 세번째 줄과 같이 나타낼 수 있다.<br>

